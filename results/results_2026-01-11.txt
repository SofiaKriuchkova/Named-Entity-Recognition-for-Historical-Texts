===============================================================================
Progress report on NER model training
Corpus: Tartu linnavolikogu (44)
11. January 2026
===============================================================================

Validation
===============================================================================

Model 1: EstBERT
--------------------------------------------------------------------------------
Model:            tartuNLP/EstBERT

learning_rate	batch_size	precision	recall	           f1	         loss
-----------------------------------------------------------------------------------------
10	0.000050	24	0.824725	0.841105	0.832835	0.128679
-----------------------------------------------------------------------------------------
9	0.000050	16	0.821413	0.838083	0.829664	0.135668
-----------------------------------------------------------------------------------------
11	0.000050	32	0.807807	0.822107	0.814894	0.130456
-----------------------------------------------------------------------------------------
0	0.000010	16	0.717189	0.731434	0.724241	0.185108
-----------------------------------------------------------------------------------------
1	0.000010	24	0.688490	0.694732	0.691597	0.199627
-----------------------------------------------------------------------------------------
2	0.000010	32	0.659861	0.655872	0.657861	0.222741
-----------------------------------------------------------------------------------------
3	0.000005	16	0.630161	0.626079	0.628113	0.264436
-----------------------------------------------------------------------------------------
4	0.000005	24	0.582123	0.553972	0.567699	0.297421
-----------------------------------------------------------------------------------------
5	0.000005	32	0.530239	0.488342	0.508429	0.340035
-----------------------------------------------------------------------------------------
6	0.000001	16	0.634586	0.182211	0.283126	0.617309
-----------------------------------------------------------------------------------------
7	0.000001	24	0.217391	0.004318	0.008467	0.687028
-----------------------------------------------------------------------------------------
8	0.000001	32	0.000000	0.000000	0.000000	1.000817



Best parameters:  learning_rate = 5e-05, batch_size = 24, epochs = 3


Results with 11 epochs:

Epoch	Training Loss	Validation Loss	Precision	Recall	          F1	  Partial Precision	Partial Recall	Partial F1
-----------------------------------------------------------------------------------------
1	0.396100	0.133235	0.800689	0.803109	0.801897	0.817047	0.819516	0.818280
-----------------------------------------------------------------------------------------
2	0.094200	0.123325	0.819858	0.844991	0.832235	0.839548	0.865285	0.852222
-----------------------------------------------------------------------------------------
3	0.056400	0.129701	0.808230	0.848014	0.827644	0.824280	0.864853	0.844079
-----------------------------------------------------------------------------------------
4	0.042300	0.135481	0.818482	0.856649	0.837131	0.832508	0.871330	0.851477
-----------------------------------------------------------------------------------------
5	0.031000	0.137096	0.849292	0.854059	0.851668	0.864319	0.869171	0.866738
-----------------------------------------------------------------------------------------
6	0.026400	0.169824	0.832189	0.837219	0.834697	0.847639	0.852763	0.850194
-----------------------------------------------------------------------------------------
7	0.020000	0.157708	0.847688	0.862694	0.855125	0.860840	0.876079	0.868393
-----------------------------------------------------------------------------------------
8	0.017200	0.167669	0.829742	0.848014	0.838779	0.845796	0.864421	0.855007
-----------------------------------------------------------------------------------------
9	0.014100	0.173445	0.831045	0.862263	0.846366	0.846026	0.877807	0.861623
-----------------------------------------------------------------------------------------
10	0.013500	0.181095	0.835225	0.857945	0.846432	0.846995	0.870035	0.858360
-----------------------------------------------------------------------------------------
11	0.012900	0.190372	0.849892	0.853195	0.851541	0.862796	0.866149	0.864469

 Precision: 0.8477
 Recall:    0.8627
 F1 Score:  0.8551
 Loss:      0.1577


	Results on the Test set (evaluation with nervaluate)
	======================================================================
	
Strict matching (exact boundary + correct type):
  Precision: 0.7950
  Recall:    0.8003
  F1 Score:  0.7976

Partial matching:
  Precision: 0.8082
  Recall:    0.8136
  F1 Score:  0.8109

Loss: 0.3026

=== Per-entity results (strict) ===
LAW         P=0.4038  R=0.3481  F1=0.3739
LOC         P=0.7281  R=0.6817  F1=0.7042
MONEY       P=0.7481  R=0.8109  F1=0.7782
ORG         P=0.8298  R=0.8517  F1=0.8406
PER         P=0.9273  R=0.9382  F1=0.9327
POSITION    P=0.8571  R=0.8824  F1=0.8696


Model 2: Est-RoBERTa
--------------------------------------------------------------------------------
Model: EMBEDDIA/est-roberta

learning_rate	batch_size	precision	recall	           f1	          loss
-----------------------------------------------------------------------------------------
10	0.000050	24	0.878343	0.879102	0.878722	0.094898
-----------------------------------------------------------------------------------------
9	0.000050	16	0.860844	0.889465	0.874920	0.098612
-----------------------------------------------------------------------------------------
11	0.000050	32	0.857983	0.881693	0.869676	0.095768
-----------------------------------------------------------------------------------------
0	0.000010	16	0.787296	0.813472	0.800170	0.134993
-----------------------------------------------------------------------------------------
1	0.000010	24	0.788875	0.808290	0.798464	0.141677
-----------------------------------------------------------------------------------------
2	0.000010	32	0.765903	0.779793	0.772786	0.157640
-----------------------------------------------------------------------------------------
3	0.000005	16	0.711384	0.725820	0.718530	0.195959
-----------------------------------------------------------------------------------------
4	0.000005	24	0.621553	0.632556	0.627006	0.239172
-----------------------------------------------------------------------------------------
5	0.000005	32	0.524603	0.556995	0.540314	0.290478
-----------------------------------------------------------------------------------------
6	0.000001	16	0.455947	0.089378	0.149458	0.617717
-----------------------------------------------------------------------------------------
7	0.000001	24	0.000000	0.000000	0.000000	0.879448
-----------------------------------------------------------------------------------------
8	0.000001	32	0.000000	0.000000	0.000000	1.213230





Best parameters:  learning_rate = 5e-05, batch_size = 24, epochs = 3


Results with 11 epochs:

Epoch	Training Loss	Validation Loss	Precision	Recall	          F1	  Partial Precision	Partial Recall	Partial F1
-----------------------------------------------------------------------------------------
1	0.166700	0.115056	0.829691	0.868739	0.848766	0.848660	0.888601	0.868171
-----------------------------------------------------------------------------------------
2	0.077500	0.116350	0.810693	0.883851	0.845693	0.823762	0.898100	0.859327
-----------------------------------------------------------------------------------------
3	0.056400	0.103908	0.856848	0.896805	0.876371	0.868812	0.909326	0.888608
-----------------------------------------------------------------------------------------
4	0.047000	0.120096	0.871532	0.881693	0.876583	0.886897	0.897237	0.892037
-----------------------------------------------------------------------------------------
5	0.036500	0.106551	0.868477	0.883851	0.876097	0.880781	0.896373	0.888508
-----------------------------------------------------------------------------------------
6	0.032100	0.127021	0.867949	0.876943	0.872423	0.880769	0.889896	0.885309
-----------------------------------------------------------------------------------------
7	0.028800	0.128227	0.868674	0.896805	0.882515	0.881639	0.910190	0.895687
-----------------------------------------------------------------------------------------
8	0.024800	0.128364	0.867006	0.883851	0.875347	0.880983	0.898100	0.889459
-----------------------------------------------------------------------------------------
9	0.018500	0.135810	0.863960	0.891192	0.877365	0.875680	0.903282	0.889267
-----------------------------------------------------------------------------------------
10	0.017700	0.143957	0.864098	0.881261	0.872595	0.877223	0.894646	0.885849
-----------------------------------------------------------------------------------------
11	0.016700	0.140034	0.871459	0.889896	0.880581	0.884567	0.903282	0.893826



  Precision: 0.8687
  Recall:    0.8968
  F1 Score:  0.8825
  Loss:      0.1282

         Results on the Test set (evaluation with nervaluate)
	======================================================================


Strict matching (exact boundary + correct type):
  Precision: 0.8166
  Recall:    0.8327
  F1 Score:  0.8246

Partial matching:
  Precision: 0.8344
  Recall:    0.8508
  F1 Score:  0.8425

Loss: 0.2598


=== Per-entity results (strict) ===
LAW         P=0.6267  R=0.5193  F1=0.5680
LOC         P=0.6906  R=0.7404  F1=0.7146
MONEY       P=0.7732  R=0.8235  F1=0.7976
ORG         P=0.8514  R=0.8499  F1=0.8506
PER         P=0.9609  R=0.9750  F1=0.9679
POSITION    P=0.8601  R=0.9044  F1=0.8817






Model 3: wikibert
--------------------------------------------------------------------------------
Model: TurkuNLP/wikibert-base-et-cased

learning_rate	batch_size	precision	recall	           f1	          loss
-----------------------------------------------------------------------------------------
10	0.000050	24	0.839882	0.858377	0.849028	0.122815
-----------------------------------------------------------------------------------------
9	0.000050	16	0.837229	0.850604	0.843864	0.126169
-----------------------------------------------------------------------------------------
11	0.000050	32	0.822983	0.841105	0.831945	0.124239
-----------------------------------------------------------------------------------------
0	0.000010	16	0.761987	0.761658	0.761823	0.162386
-----------------------------------------------------------------------------------------
1	0.000010	24	0.740009	0.743523	0.741762	0.179113
-----------------------------------------------------------------------------------------
2	0.000010	32	0.714347	0.715889	0.715118	0.196454
-----------------------------------------------------------------------------------------
3	0.000005	16	0.664363	0.664076	0.664219	0.231815
-----------------------------------------------------------------------------------------
4	0.000005	24	0.620309	0.606649	0.613403	0.256420
-----------------------------------------------------------------------------------------
5	0.000005	32	0.592851	0.551382	0.571365	0.291975
-----------------------------------------------------------------------------------------
6	0.000001	16	0.552319	0.221071	0.315757	0.567532
-----------------------------------------------------------------------------------------
7	0.000001	24	0.698000	0.150691	0.247869	0.628412
-----------------------------------------------------------------------------------------
8	0.000001	32	0.591667	0.061313	0.111111	0.683752

Best parameters:  learning_rate = 5e-05, batch_size = 24, epochs = 3


Results with 10 epochs:

Epoch	Training Loss	Validation Loss	Precision	Recall	          F1	   Partial Precision	Partial Recall	Partial F1
-----------------------------------------------------------------------------------------
1	0.392100	0.131420	0.795522	0.813040	0.804185	0.814533	0.832470	0.823404
-----------------------------------------------------------------------------------------
2	0.084100	0.121399	0.816327	0.846287	0.831037	0.832986	0.863558	0.847997	
-----------------------------------------------------------------------------------------
3	0.049600	0.127249	0.812785	0.845423	0.828783	0.828560	0.861831	0.844868
-----------------------------------------------------------------------------------------
4	0.034800	0.145820	0.841054	0.854491	0.847719	0.857204	0.870898	0.863997	
-----------------------------------------------------------------------------------------
5	0.025800	0.147062	0.848156	0.844128	0.846137	0.864208	0.860104	0.862151
-----------------------------------------------------------------------------------------
6	0.023200	0.168238	0.854506	0.859672	0.857081	0.870386	0.875648	0.873009	
-----------------------------------------------------------------------------------------
7	0.019000	0.152561	0.854140	0.859672	0.856897	0.870871	0.876511	0.873682	
-----------------------------------------------------------------------------------------
8	0.015500	0.154328	0.828571	0.851468	0.839864	0.843277	0.866580	0.854770
-----------------------------------------------------------------------------------------
9	0.012600	0.176833	0.841791	0.852332	0.847029	0.857569	0.868307	0.862905
-----------------------------------------------------------------------------------------
10	0.012500	0.173099	0.844189	0.856218	0.850161	0.861643	0.873921	0.867738	

Results:
  Precision: 0.8545
  Recall:    0.8597
  F1 Score:  0.8571
  Loss:      0.1682


         Results on the Test set (evaluation with nervaluate)
	======================================================================
	

Strict matching (exact boundary + correct type):
  Precision: 0.7793
  Recall:    0.7979
  F1 Score:  0.7885

Partial matching:
  Precision: 0.7988
  Recall:    0.8179
  F1 Score:  0.8082

Loss: 0.3217


=== Per-entity results (strict) ===
LAW         P=0.5137  R=0.4144  F1=0.4587
LOC         P=0.6283  R=0.6683  F1=0.6477
MONEY       P=0.7541  R=0.8697  F1=0.8078
ORG         P=0.8234  R=0.8062  F1=0.8147
PER         P=0.9347  R=0.9471  F1=0.9408
POSITION    P=0.8304  R=0.8824  F1=0.8556


Model 4: EstBERT_NER
--------------------------------------------------------------------------------
Model: tartuNLP/EstBERT_NER

Strict matching (exact boundary + correct type):
  Precision: 0.7133
  Recall:    0.4596
  F1 Score:  0.5590

Partial matching:
  Precision: 0.7786
  Recall:    0.5017
  F1 Score:  0.6102

Loss: 0.6498

=== Per-entity results (strict) ===
LOC         P=0.3446  R=0.1876  F1=0.2430
ORG         P=0.7850  R=0.3421  F1=0.4766
PER         P=0.8294  R=0.8868  F1=0.8571